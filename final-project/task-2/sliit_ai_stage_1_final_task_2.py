# -*- coding: utf-8 -*-
"""sliit-ai-stage-1-final-task-2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t2rInFw9liKBV9ajBxQxdhtzM9gK0hkW
"""

import pandas as pd
import numpy as np
import nltk
import string
import re
from nltk.stem.porter import PorterStemmer
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Load the dataset
df = pd.read_csv("Tweets.csv")

# Step 1 – Select required columns
df = df[["airline_sentiment", "text"]]

# Display head and info of the modified DataFrame
print("DataFrame head after selecting columns:")
print(df.head())
print("\nDataFrame info:")
print(df.info())
print("\nDataFrame Shape:")
print(df.shape)

# Step 2 – Preprocess Text
# Download necessary NLTK resources
nltk.download("stopwords")
nltk.download("punkt")

ps = PorterStemmer()

def clean_text(text):
    text = str(text) # Convert to string to handle potential NaNs
    text = text.lower()
    # Remove URLs
    text = re.sub(r'http.?://[^\s]+[\s]?', '', text)
    # Tokenize
    text = nltk.word_tokenize(text)

    # Remove stop words
    y = []
    for i in text:
        if i not in stopwords.words('english'):
            y.append(i)
    text = y[:]

    # Stemming
    y.clear()
    for i in text:
        y.append(ps.stem(i))

    return " ".join(y)

nltk.download('punkt_tab')

# Apply "clean_text" function to "text" column
df["text_cleaned"] = df["text"].apply(clean_text)

df.head(3)

# Display head with the new column
print("\nDataFrame head after text cleaning:")
print(df[["text", "text_cleaned"]].head())

# Step 3 – Feature Extraction
# Create TfidfVectorizer
tfidf = TfidfVectorizer(max_features=3000)

# Generate TF-IDF vector representation
X = tfidf.fit_transform(df["text_cleaned"]).toarray()

X.shape

# Convert the column “airline_sentiment” to an array
Y = df["airline_sentiment"].values

print(f"\nShape of feature matrix X: {X.shape}")
print(f"Shape of target array Y: {Y.shape}")

# Step 4 – Train Model
# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=2)

print(f"\nShape of X_train: {X_train.shape}")
print(f"Shape of X_test: {X_test.shape}")

# Train a Multinomial Naïve Bayes classifier
print("\n--- Multinomial Naïve Bayes Classifier ---")
nb_model = MultinomialNB()
nb_model.fit(X_train, y_train)
y_pred_nb = nb_model.predict(X_test)
accuracy_nb = accuracy_score(y_test, y_pred_nb)
print(f"Accuracy (Multinomial Naïve Bayes): {accuracy_nb:.4f}")

# Train a Random Forest classifier (using the provided snippet logic)
print("\n--- Random Forest Classifier ---")
rf_model = RandomForestClassifier(random_state=2) # Set random_state for reproducibility
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)
accuracy_rf = accuracy_score(y_test, y_pred_rf)
print(f"Accuracy (Random Forest): {accuracy_rf:.4f}")

y_pred = rf_model.predict(X_test)

print(accuracy_score(y_test,y_pred))

# Filter the DataFrame for "neutral" sentiment
neutral_tweets = df[df['airline_sentiment'] == 'neutral']

# Count the number of unique tweets in the 'text' column for the filtered data
unique_neutral_count = neutral_tweets['text'].nunique()

print(f"Total rows with 'neutral' sentiment: {len(neutral_tweets)}")
print(f"Number of unique tweets with 'neutral' sentiment: {unique_neutral_count}")

# Get the count of instances for each unique sentiment class
sentiment_counts = df['airline_sentiment'].value_counts()

# Print all sentiment counts for context
print("Sentiment Class Counts:")
print(sentiment_counts)

# Extract and print the count for "negative" sentiment
negative_count = sentiment_counts['negative']
print(f"\nNumber of 'negative' sentiment instances: {negative_count}")

# Train a Multinomial Naïve Bayes classifier
nb_model = MultinomialNB()
nb_model.fit(X_train, y_train)
y_pred_nb = nb_model.predict(X_test)
accuracy_nb = accuracy_score(y_test, y_pred_nb)

# Train a Random Forest classifier
rf_model = RandomForestClassifier(random_state=2, n_jobs=-1)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)
accuracy_rf = accuracy_score(y_test, y_pred_rf)

print(accuracy_nb)
print(accuracy_rf)

